{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are answers to the question, which are part of the assignment described [here.](http://web.stanford.edu/class/cs224n/assignments/a4.pdf)\n",
    "# 1(g)\n",
    "\n",
    "    The masks set the input to the softmax for 'pad' tokens to -inf. Then the output of softmax for these tokens equals 0. \n",
    "    This cause the tokens to be ignored when calculating attention output. \n",
    "    It is necessary because for the attention we care only about actual context of a sentence (represented by values of a hidden state in the Encoder),\n",
    "    because it brings some information to the model. 'pad' tokens do not brings much relevant information.\n",
    "    Including 'pad' tokens for short sentences would cause weight assigned to hidden states corresponding to normal words to be smaller. \n",
    "# 1(j) \n",
    "    * Dot product attention: doesn't introduce additional parameters to the model, requires the 2 vector to be of the same shape \n",
    "    * Multiplicative attention: introduce additional parameters to the model, enables to calculate attention between vectors of different shape\n",
    "    * Additive attention: slower to calculate, more operations, more learnable parameters\n",
    "# 2(a)\n",
    "    * Source Sentence: Aqu´ı otro de mis favoritos, “La noche estrellada”.\n",
    "    Reference Translation: So another one of my favorites, “The Starry Night”.\n",
    "    NMT Translation: Here’s another favorite of my favorites, “The Starry Night”.\n",
    "        1. Double favourite.\n",
    "        2. Two parts of the English sentence with favourite make sense separately so they are highly probable to be returned by a model.\n",
    "        3. Make a model to notice that a similar word is already in the text and make probability of using it again lower.\n",
    "        Increase beam size in beam search.\n",
    "\n",
    "    * Source Sentence: Ustedes saben que lo que yo hago es escribir para los ni˜nos, y,\n",
    "    de hecho, probablemente soy el autor para ni˜nos, ms ledo en los EEUU.\n",
    "    Reference Translation: You know, what I do is write for children, and I’m probably America’s\n",
    "    most widely read children’s author, in fact.\n",
    "    NMT Translation: You know what I do is write for children, and in fact, I’m probably the\n",
    "    author for children, more reading in the U.S.\n",
    "        1. Too direct translation, incorrect gramatically in English.\n",
    "        2. Model might have put too much weight on specific words.\n",
    "        3. Increase number of parameters in the model, increase beam size.\n",
    "    \n",
    "    * Source Sentence: Un amigo me hizo eso – Richard Bolingbroke.\n",
    "    Reference Translation: A friend of mine did that – Richard Bolingbroke.\n",
    "    NMT Translation: A friend of mine did that – Richard <unk>\n",
    "        1. Unknown token.\n",
    "        2. Not all words can in included in the vocabulary.\n",
    "        3. Detect named entitites and copy them directly in the model.\n",
    "    * Source Sentence: Solo tienes que dar vuelta a la manzana para verlo como una\n",
    "    epifan´ıa.\n",
    "    Reference Translation: You’ve just got to go around the block to see it as an epiphany.\n",
    "    NMT Translation: You just have to go back to the apple to see it as a epiphany.\n",
    "        1. Sentence does not make sense.\n",
    "        2. Manzana has 2 meanings: block and apple. The model picked the wrong one.\n",
    "        3. Use context dependent embeddings of source language. \n",
    "    * Source Sentence: Ella salv´o mi vida al permitirme entrar al ba˜no de la sala de\n",
    "    profesores.\n",
    "    Reference Translation: She saved my life by letting me go to the bathroom in the teachers’\n",
    "    lounge.\n",
    "    NMT Translation: She saved my life by letting me go to the bathroom in the women’s room.\n",
    "        1. The output sentence does not contain information about teachers.\n",
    "        2. Model picked the popular term that matched the context. \n",
    "    * Source Sentence: Eso es m´as de 100,000 hect´areas.\n",
    "    Reference Translation: That’s more than 250 thousand acres.\n",
    "    NMT Translation: That’s over 100,000 acres.\n",
    "        1. Both translations seems to be incorrect.\n",
    "        2. Model maybe picked the more common word - acres? \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true,
     "name": "#%%"
    }
   },
   "source": [
    "# 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_in_n_grams_cnt(n_gram, n_grams):\n",
    "    return sum([int(n_gram == target_n_gram) for target_n_gram in n_grams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_n_gram_precision(candidate_translation, reference_translations, n):\n",
    "    candidate_n_grams = [n_gram for n_gram in ngrams(candidate_translation.split(), n)]\n",
    "    references_n_grams = [[n_gram for n_gram in ngrams(r.split(), n)] for r in reference_translations]\n",
    "    nominator = 0\n",
    "    for c_n_gram in candidate_n_grams:\n",
    "        c_n_gram_in_c_cnt = n_gram_in_n_grams_cnt(c_n_gram, candidate_n_grams)\n",
    "        c_n_gram_in_r_cnts = [n_gram_in_n_grams_cnt(c_n_gram, r_n_grams) for r_n_grams in references_n_grams]\n",
    "        c_n_gram_in_r_cnt_max = max(c_n_gram_in_r_cnts)\n",
    "        nominator += min(c_n_gram_in_r_cnt_max, c_n_gram_in_c_cnt)\n",
    "    return nominator / len(candidate_n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate_translation, reference_translations):\n",
    "    c_len = len(candidate_translation)\n",
    "    r_lens = np.asarray([len(r) for r in reference_translations])\n",
    "    c_r_diffs = np.abs(r_lens - c_len)\n",
    "    r_star = r_lens[np.argmin(c_r_diffs)].min()\n",
    "    if c_len >= r_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(1-r_star / c_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEU(candidate_translation, reference_translations, lambdas):\n",
    "    prec_sum = 0\n",
    "    for i, l in enumerate(lambdas):\n",
    "        n = i+1\n",
    "        prec_sum += l * modified_n_gram_precision(candidate_translation, reference_translations, n)\n",
    "    BP = brevity_penalty(candidate_translation, reference_translations)\n",
    "    return BP * np.exp(prec_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'el amor todo lo puede'\n",
    "r1 = 'love can always find a way'\n",
    "r2 = 'love makes anything possible'\n",
    "c1 = 'the love can always do'\n",
    "c2 = 'love can make anything possible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4451047614095538"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(c1, [r1, r2], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9155408290138962"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(c2, [r1, r2], [0.5, 0.5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a4",
   "language": "python",
   "name": "local_nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are answers to the question, which are part of the assignment described [here.](http://web.stanford.edu/class/cs224n/assignments/a4.pdf)\n",
    "# 1(g)\n",
    "\n",
    "    The masks set the input to the softmax for 'pad' tokens to -inf. Then the output of softmax for these tokens equals 0. \n",
    "    This cause the tokens to be ignored when calculating attention output. \n",
    "    It is necessary because for the attention we care only about actual context of a sentence (represented by values of a hidden state in the Encoder),\n",
    "    because it brings some information to the model. 'pad' tokens do not brings much relevant information.\n",
    "    Including 'pad' tokens for short sentences would cause weight assigned to hidden states corresponding to normal words to be smaller. \n",
    "# 1(j) \n",
    "    * Dot product attention: doesn't introduce additional parameters to the model, requires the 2 vector to be of the same shape \n",
    "    * Multiplicative attention: introduce additional parameters to the model, enables to calculate attention between vectors of different shape\n",
    "    * Additive attention: slower to calculate, more operations, more learnable parameters\n",
    "# 2(a)\n",
    "    * Source Sentence: Aqu´ı otro de mis favoritos, “La noche estrellada”.\n",
    "    Reference Translation: So another one of my favorites, “The Starry Night”.\n",
    "    NMT Translation: Here’s another favorite of my favorites, “The Starry Night”.\n",
    "        1. Double favourite.\n",
    "        2. Two parts of the English sentence with favourite make sense separately so they are highly probable to be returned by a model.\n",
    "        3. Make a model to notice that a similar word is already in the text and make probability of using it again lower.\n",
    "        Increase beam size in beam search.\n",
    "\n",
    "    * Source Sentence: Ustedes saben que lo que yo hago es escribir para los ni˜nos, y,\n",
    "    de hecho, probablemente soy el autor para ni˜nos, ms ledo en los EEUU.\n",
    "    Reference Translation: You know, what I do is write for children, and I’m probably America’s\n",
    "    most widely read children’s author, in fact.\n",
    "    NMT Translation: You know what I do is write for children, and in fact, I’m probably the\n",
    "    author for children, more reading in the U.S.\n",
    "        1. Too direct translation, incorrect gramatically in English.\n",
    "        2. Model might have put too much weight on specific words.\n",
    "        3. Increase number of parameters in the model, increase beam size.\n",
    "    \n",
    "    * Source Sentence: Un amigo me hizo eso – Richard Bolingbroke.\n",
    "    Reference Translation: A friend of mine did that – Richard Bolingbroke.\n",
    "    NMT Translation: A friend of mine did that – Richard <unk>\n",
    "        1. Unknown token.\n",
    "        2. Not all words can in included in the vocabulary.\n",
    "        3. Detect named entitites and copy them directly in the model.\n",
    "    * Source Sentence: Solo tienes que dar vuelta a la manzana para verlo como una\n",
    "    epifan´ıa.\n",
    "    Reference Translation: You’ve just got to go around the block to see it as an epiphany.\n",
    "    NMT Translation: You just have to go back to the apple to see it as a epiphany.\n",
    "        1. Sentence does not make sense.\n",
    "        2. Manzana has 2 meanings: block and apple. The model picked the wrong one.\n",
    "        3. Use context dependent embeddings of source language. \n",
    "    * Source Sentence: Ella salv´o mi vida al permitirme entrar al ba˜no de la sala de\n",
    "    profesores.\n",
    "    Reference Translation: She saved my life by letting me go to the bathroom in the teachers’\n",
    "    lounge.\n",
    "    NMT Translation: She saved my life by letting me go to the bathroom in the women’s room.\n",
    "        1. The output sentence does not contain information about teachers.\n",
    "        2. Model picked the popular term that matched the context. \n",
    "    * Source Sentence: Eso es m´as de 100,000 hect´areas.\n",
    "    Reference Translation: That’s more than 250 thousand acres.\n",
    "    NMT Translation: That’s over 100,000 acres.\n",
    "        1. Both translations seems to be incorrect.\n",
    "        2. Model maybe picked the more common word - acres? \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y as noms, el tmpano muestra un lado diferente de su personalidad.\n",
      "And just like that,  the iceberg shows you a different side of its personality.\n",
      "And so the iceberg the iceberg shows a different side of your personality.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk NR==61 en_es_data/test.es\n",
    "awk NR==61 en_es_data/test.en\n",
    "awk NR==61 outputs/test_outputs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Error: 'Your' instead of 'its', duplicate of work the iceberg.\n",
    "2. Reason: Su apart from 'its' is also a formal form of 'your' and 'your personality' seems to be much more reasonable than 'its personality'.\n",
    "3. Fix: Track somehow the subject of the whole sentence and use this information to decide if 'its' or 'your' is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entonces, dos parejas cada una con un beb.\n",
      "So two couples each conceiving one baby.\n",
      "So, two couples in a baby.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "awk NR==64 en_es_data/test.es\n",
    "awk NR==64 en_es_data/test.en\n",
    "awk NR==64 outputs/test_outputs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Error: 'In a baby' instead of 'conceiving one baby'.\n",
    "2. Reason: 'Con' is a preposition but in English the best word in this sentence for it is 'having' or 'conveiving'. \n",
    "3. Fix: We need to somehow know that 'in a baby' is rather strange expression - maybe adding beam search run backward (so it would include baby for sure) whould help?   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%"
    }
   },
   "source": [
    "# 2(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram_in_n_grams_cnt(n_gram, n_grams):\n",
    "    return sum([int(n_gram == target_n_gram) for target_n_gram in n_grams])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modified_n_gram_precision(candidate_translation, reference_translations, n):\n",
    "    candidate_n_grams = [n_gram for n_gram in ngrams(candidate_translation.split(), n)]\n",
    "    references_n_grams = [[n_gram for n_gram in ngrams(r.split(), n)] for r in reference_translations]\n",
    "    nominator = 0\n",
    "    for c_n_gram in candidate_n_grams:\n",
    "        c_n_gram_in_c_cnt = n_gram_in_n_grams_cnt(c_n_gram, candidate_n_grams)\n",
    "        c_n_gram_in_r_cnts = [n_gram_in_n_grams_cnt(c_n_gram, r_n_grams) for r_n_grams in references_n_grams]\n",
    "        c_n_gram_in_r_cnt_max = max(c_n_gram_in_r_cnts)\n",
    "        nominator += min(c_n_gram_in_r_cnt_max, c_n_gram_in_c_cnt)\n",
    "    return nominator / len(candidate_n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_cnt(sentence):\n",
    "    return len(re.findall(r'\\w+', sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brevity_penalty(candidate_translation, reference_translations):\n",
    "    c_len = words_cnt(candidate_translation)\n",
    "    r_lens = np.asarray([words_cnt(r) for r in reference_translations])\n",
    "    c_r_diffs = np.abs(r_lens - c_len)\n",
    "    all_argmin = np.argwhere(c_r_diffs == c_r_diffs.min())\n",
    "    r_star = r_lens[all_argmin].min()\n",
    "    if c_len >= r_star:\n",
    "        return 1\n",
    "    else:\n",
    "        return np.exp(1-r_star / c_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEU(candidate_translation, reference_translations, lambdas):\n",
    "    prec_sum = 0\n",
    "    for i, lamb in enumerate(lambdas):\n",
    "        n = i+1\n",
    "        prec_sum += lamb * np.log(modified_n_gram_precision(candidate_translation, reference_translations, n))\n",
    "    BP = brevity_penalty(candidate_translation, reference_translations)\n",
    "    return BP * np.exp(prec_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'el amor todo lo puede'\n",
    "r1 = 'love can always find a way'\n",
    "r2 = 'love makes anything possible'\n",
    "c1 = 'the love can always do'\n",
    "c2 = 'love can make anything possible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5477225575051662"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(c1, [r1, r2], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6324555320336759"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(c2, [r1, r2], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculated manually \n",
    "### c1:\n",
    "\n",
    "#### 1-grams\n",
    "* the, love, can, always, do \n",
    "* p1: (0 + 1 + 1 + 1 + 0) / 5 = 3/5\n",
    "\n",
    "#### 2-grams\n",
    "* the love, love can, can always, always do\n",
    "* p2: (0 + 1 + 1 + 0) / 4 = 1/2\n",
    "\n",
    "#### BP\n",
    "* c: 5\n",
    "* r*: 4\n",
    "* c > r* so BP = 1\n",
    "\n",
    "#### BLEU\n",
    "1 * exp(0.5 * log (3/5) + 0.5 * log(1/2)) = 0.55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i)\n",
    "I agree - second sentence seems to be better translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.448437301984003"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(c1, [r1], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25890539701513365"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLEU(c2, [r1], [0.5, 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now according to BLEU the first translation is better. I don't agree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to data availability, NMT systems are often evaluated with respect to only a\n",
    "single reference translation. This may be problematic because often the meaning of a sentence can\n",
    "be expressed in a few different ways, using different words and n-grams. \n",
    "With only one single reference translation we miss information that\n",
    "some n-grams are meaningful if they don't occur in the reference translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Advantages of BLEU, compared to human evaluation, as an evaluation metric for Machine Translation:\n",
    "    * Can be calculated automatically for a new model - so we don't need a human to evaluate the results of a model after it has been trained.\n",
    "    * We gather the reference translations to be used for BLEU calculation once. Because of this the results are comparable for different models and across time. They don't depend on human evalator, her mood etc.\n",
    "    * Quick to calculate.\n",
    "* Disadvantages:\n",
    "    * Does not take into account whole translation and if it makes sense and sounds reasonable in the output language - because it's based only on the n-grams.\n",
    "    * Human evaluation should be more accurate, especially where there are not many reference sentences gathered."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a4",
   "language": "python",
   "name": "local_nmt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
